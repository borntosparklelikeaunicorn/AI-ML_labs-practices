{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IyXzTLyar_fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from abc import abstractmethod\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nVCn38u2r_fh"
      },
      "outputs": [],
      "source": [
        "def load_data(folder):\n",
        "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
        "    y_train = np.load(os.path.join(folder, 'y_train.npy'))\n",
        "    x_test = np.load(os.path.join(folder, 'x_test.npy'))\n",
        "    y_test = np.load(os.path.join(folder, 'y_test.npy'))\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D08Ws81or_fi"
      },
      "outputs": [],
      "source": [
        "def assert_preds_correct(your_preds, sklearn_preds) -> bool:\n",
        "    return np.abs(your_preds - sklearn_preds).sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lxdkvJzEr_fj"
      },
      "outputs": [],
      "source": [
        "def assert_probs_correct(your_probs, sklearn_probs) -> bool:\n",
        "    return np.abs(your_probs - sklearn_probs).mean() < 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PokJ-oLwr_fk"
      },
      "outputs": [],
      "source": [
        "# Не изменяйте код этого класса!\n",
        "class NaiveBayes:\n",
        "    def __init__(self, n_classes):\n",
        "        self.n_classes = n_classes\n",
        "        self.params = dict()\n",
        "\n",
        "    # --- PREDICTION ---\n",
        "\n",
        "    def predict(self, x, return_probs=False):\n",
        "        \"\"\"\n",
        "        x - np.array размерности [N, dim],\n",
        "        где N - количество экземпляров данных,\n",
        "        dim -размерность одного экземпляра (количество признаков).\n",
        "\n",
        "        Возвращает np.array размерности [N], содержащий номера классов для\n",
        "        соответствующих экземпляров.\n",
        "        \"\"\"\n",
        "        preds = []\n",
        "        for sample in x:\n",
        "            preds.append(\n",
        "                self.predict_single(sample, return_probs=return_probs)\n",
        "            )\n",
        "\n",
        "        if return_probs:\n",
        "            return np.array(preds, dtype='float32')\n",
        "\n",
        "        return np.array(preds, dtype='int32')\n",
        "\n",
        "    # Совет: вниманительно изучите файл подсказок к данной лабораторной\n",
        "    # и сопоставьте код с описанной математикой байесовского классификатора.\n",
        "    def predict_single(self, x, return_probs=False) -> int:\n",
        "        \"\"\"\n",
        "        Делает предсказание для одного экземпляра данных.\n",
        "\n",
        "        x - np.array размерности dim.\n",
        "\n",
        "        Возвращает номер класса, которому принадлежит x.\n",
        "        \"\"\"\n",
        "        assert len(x.shape) == 1, f'Expected a vector, but received a tensor of shape={x.shape}'\n",
        "        marginal_prob = self.compute_marginal_probability(x)  # P(x) - безусловная вероятность появления x\n",
        "\n",
        "        probs = []\n",
        "        for c in range(self.n_classes):                 # c - номер класса\n",
        "            prior = self.compute_prior(c)               # P(c) - априорная вероятность (вероятность появления класса)\n",
        "            likelihood = self.compute_likelihood(x, c)  # P(x|c) - вероятность появления x в предположении, что он принаждлежит c\n",
        "\n",
        "            # Используем теорему Байесса для просчёта условной вероятности P(c|x)\n",
        "            # P(c|x) = P(c) * P(x|c) / P(x)\n",
        "            prob = prior * likelihood / marginal_prob\n",
        "            probs.append(prob)\n",
        "\n",
        "        if return_probs:\n",
        "            return probs\n",
        "\n",
        "        return np.argmax(probs)\n",
        "\n",
        "    # Вычисляет P(x) - безусловная вероятность появления x.\n",
        "    @abstractmethod\n",
        "    def compute_marginal_probability(self, x) -> float:\n",
        "        pass\n",
        "\n",
        "    # Вычисляет P(c) - априорная вероятность появления класса c.\n",
        "    @abstractmethod\n",
        "    def compute_prior(self, c) -> float:\n",
        "        pass\n",
        "\n",
        "    # Вычисляет P(x|c) - вероятность наблюдения экземпляра x в предположении, что он принаждлежит c.\n",
        "    @abstractmethod\n",
        "    def compute_likelihood(self, x, c) -> float:\n",
        "        pass\n",
        "\n",
        "    # --- FITTING ---\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self._estimate_prior(y)\n",
        "        self._estimate_params(x, y)\n",
        "\n",
        "    @abstractmethod\n",
        "    def _estimate_prior(self, y):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _estimate_params(self, x, y):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3RPkiFdr_fn"
      },
      "source": [
        "## 1. Наивный классификатор Байеса: гауссово распределение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJTjk1pcr_fq"
      },
      "source": [
        "Напишите недостающий код, создайте и обучите модель.\n",
        "\n",
        "Пункты оценки:\n",
        "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
        "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D1UI_r4ur_fr"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = load_data('/gauss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w8wAIb8hr_fs"
      },
      "outputs": [],
      "source": [
        "# P(C_k|x) = P(x|theta) * P(C_k) / P(x)\n",
        "\n",
        "class NaiveGauss(NaiveBayes):\n",
        "    def compute_marginal_probability(self, x) -> float:\n",
        "        # Для просчёта безусловной вероятности используйте\n",
        "        # методы compute_prior и compute_likelihood.\n",
        "        # Напишите свой код здесь\n",
        "        marginal_prob = 0.0\n",
        "        for c in range(self.n_classes):\n",
        "            prior = self.compute_prior(c)\n",
        "            likelihood = self.compute_likelihood(x, c)\n",
        "            marginal_prob += prior * likelihood\n",
        "        return marginal_prob\n",
        "\n",
        "    def compute_prior(self, c) -> float:\n",
        "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
        "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
        "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
        "        return self.params['prior'][c]\n",
        "\n",
        "    def compute_likelihood(self, x, c) -> float:\n",
        "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
        "        mean = self.params['mean'][c]\n",
        "        var = self.params['var'][c]\n",
        "        likelihood = np.prod(1 / np.sqrt(2 * np.pi * var) * np.exp(-0.5 * ((x - mean) ** 2) / var))\n",
        "        return likelihood\n",
        "\n",
        "    # --- FITTING ---\n",
        "\n",
        "    def _estimate_prior(self, y):\n",
        "        # Значения априорных вероятностей сохраните в `params` с ключом 'prior'\n",
        "        class_counts = np.bincount(y, minlength=self.n_classes)\n",
        "        self.params['prior'] = class_counts / len(y)\n",
        "\n",
        "    def _estimate_params(self, x, y):\n",
        "        self.params['mean'] = []\n",
        "        self.params['var'] = []\n",
        "        for c in range(self.n_classes):\n",
        "            x_c = x[y == c]\n",
        "            mean_c = x_c.mean(axis=0)\n",
        "            var_c = x_c.var(axis=0)\n",
        "            self.params['mean'].append(mean_c)\n",
        "            self.params['var'].append(var_c)\n",
        "        self.params['mean'] = np.array(self.params['mean'])\n",
        "        self.params['var'] = np.array(self.params['var'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1L1kdlSYr_ft"
      },
      "outputs": [],
      "source": [
        "# Создайте и обучите модель\n",
        "our_nb = NaiveGauss(n_classes=np.unique(y_train).shape[0])\n",
        "our_nb.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkhxNWV8r_fv",
        "outputId": "91baf508-7fc5-47e6-e470-2cbe6b65b465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Оцените качество модели\n",
        "our_preds = our_nb.predict(x_test)\n",
        "our_probs = our_nb.predict(x_test, return_probs=True)\n",
        "\n",
        "accuracy = accuracy_score(y_test, our_preds)\n",
        "print(f'Accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6rQQNRIr_fx",
        "outputId": "8dd2bff9-f7c2-45af-dbd5-b11b5c03f04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Предсказанные классы и вероятности нашей модели совпадают с классами и вероятностями модели sklearn🥳\n"
          ]
        }
      ],
      "source": [
        "# Сравните вашу модель с аналогом sklearn (GaussianNB)\n",
        "skl_nb = GaussianNB()\n",
        "skl_nb.fit(x_train, y_train)\n",
        "\n",
        "skl_preds = skl_nb.predict(x_test)\n",
        "skl_probs = skl_nb.predict_proba(x_test)\n",
        "\n",
        "skl_accuracy = accuracy_score(y_test, skl_preds)\n",
        "print(f'Accuracy: {skl_accuracy:.2f}')\n",
        "\n",
        "assert assert_preds_correct(our_preds, skl_preds), \"Предсказанные классы нашей модели и модели sklearn НЕ совпадают!\"\n",
        "assert assert_probs_correct(our_probs, skl_probs), \"Вероятности нашей модели и модели sklearn НЕ совпадают!\"\n",
        "\n",
        "print(\"Предсказанные классы и вероятности нашей модели совпадают с классами и вероятностями модели sklearn🥳\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdL0fS0Br_fy"
      },
      "source": [
        "## 2. Доп. задания (любое на выбор, опционально)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAIFiRTQr_fy"
      },
      "source": [
        "### 2.1  Упрощение наивного классификатора Байеса для гауссова распределения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lodBY-b2r_fy"
      },
      "source": [
        "Уберите из класса NaiveBayes 'лишние' вычисления и удалите код, что соответствует этим вычислениям. Под 'лишним' подразумеваются вещи, что не влияют на итоговое решение о принадлежности классу (значения вероятностей при этом могу стать некорректными, но в данном задании это допустимо).\n",
        "\n",
        "Напишите в клетке ниже код упрощенного 'классификатора Гаусса' и убедитесь, что его ответы (не значения вероятностей) совпадают с ответами классификатора из задания 1. Для сравнения ответов используйте функцию `assert_preds_correct`.\n",
        "\n",
        "Указание: работайте в предположении, что классы равновероятны.\n",
        "\n",
        "Подсказка: упростить необходимо метод `predict_single`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "z6KfQPslr_fz"
      },
      "outputs": [],
      "source": [
        "# Напишите обновленный код модели здесь\n",
        "class NaiveGaussSimple(NaiveBayes):\n",
        "    def compute_prior(self, c) -> float:\n",
        "        return 1.0\n",
        "\n",
        "    def compute_likelihood(self, x, c) -> float:\n",
        "        mean = self.params['mean'][c]\n",
        "        var = self.params['var'][c]\n",
        "        likelihood = np.prod(1 / np.sqrt(2 * np.pi * var) * np.exp(-0.5 * ((x - mean) ** 2) / var))\n",
        "        return likelihood\n",
        "\n",
        "    def predict_single(self, x, return_probs=False) -> int:\n",
        "        probs = []\n",
        "        for c in range(self.n_classes):\n",
        "            likelihood = self.compute_likelihood(x, c)  # P(x|c)\n",
        "            probs.append(likelihood)\n",
        "\n",
        "        return np.argmax(probs)\n",
        "\n",
        "    def _estimate_params(self, x, y):\n",
        "        self.params['mean'] = []\n",
        "        self.params['var'] = []\n",
        "        for c in range(self.n_classes):\n",
        "            x_c = x[y == c]\n",
        "            mean_c = x_c.mean(axis=0)\n",
        "            var_c = x_c.var(axis=0)\n",
        "            self.params['mean'].append(mean_c)\n",
        "            self.params['var'].append(var_c)\n",
        "        self.params['mean'] = np.array(self.params['mean'])\n",
        "        self.params['var'] = np.array(self.params['var'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IpE7GbuGr_fz"
      },
      "outputs": [],
      "source": [
        "# Создайте и обучите модель\n",
        "simple_nb = NaiveGaussSimple(n_classes=np.unique(y_train).shape[0])\n",
        "simple_nb.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eBRf0fPr_f0",
        "outputId": "991d103b-0959-445f-cf85-ad7286b4cb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Оцените качество модели\n",
        "simple_nb_preds = simple_nb.predict(x_test)\n",
        "\n",
        "simple_nb_accuracy = accuracy_score(y_test, simple_nb_preds)\n",
        "print(f'Accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0Kzi8gSr_f0",
        "outputId": "22a15280-da54-4611-ac80-572034a97b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказанные классы совпадают🥳\n"
          ]
        }
      ],
      "source": [
        "# Сравните вашу модель с моделью из задания 1\n",
        "assert assert_preds_correct(our_preds, simple_nb_preds), \"Предсказанные классы НЕ совпадают!\"\n",
        "\n",
        "print(\"Предсказанные классы совпадают🥳\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8w8cA6Ur_f1"
      },
      "outputs": [],
      "source": [
        "# Объясните в комментариях к этой клетке суть проделанных изменений: почему удаленный код является лишним?\n",
        "# Раз мы предполагаем, что классы равноверояны, то мы можем убрать расчет априорных вероятностей и не учитывать их в дальнейшем,\n",
        "# ведь вероятность каждго класса одинаковая и не влияет на выбор класса, который мы предсказываем\n",
        "# Также был убран подсчет безусловной вероятности появления x, т.к. нам в целом важен тот класс, для которого вероятность максимальна,\n",
        "# а без P(x) относительные соотношения между вероятностями сохраняются.\n",
        "# Соответственно, в predict_single были убраны подсчеты априорной и безусловной вероятностей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3VzjLdyr_f1"
      },
      "source": [
        "### 2.1  Наивный классификатор Байеса: мультиномиальное распределения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doEjwPc0r_f2"
      },
      "source": [
        "Напишите недостающий код, создайте и обучите модель.\n",
        "\n",
        "Подсказка: в определении функции правдоподобия много факториалов. Для избежания численного переполнения посчитайте сначала логарифм функции правдоподобия (на бумаге), после примените экспоненту для получения значения вероятности.\n",
        "\n",
        "Пункты оценки:\n",
        "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
        "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True.\n",
        "\n",
        "Сложность: математический гений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50NpvLwrr_f2"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = load_data('multinomial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmTAYf7Xr_f2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "При желании данный класс можно переписать с нуля. Изменения должны сопровождаться комментариями.\n",
        "\"\"\"\n",
        "class NaiveMultinomial(NaiveBayes):\n",
        "    def compute_marginal_probability(self, x) -> float:\n",
        "        # Для просчёта безусловной вероятности используйте\n",
        "        # методы compute_prior и compute_likelihood.\n",
        "        # Напишите свой код здесь\n",
        "        pass\n",
        "\n",
        "    def compute_prior(self, c) -> float:\n",
        "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
        "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
        "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
        "        # Напишите свой код здесь\n",
        "        pass\n",
        "\n",
        "    def compute_likelihood(self, x, c) -> float:\n",
        "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
        "        # Напишите свой код здесь\n",
        "        pass\n",
        "\n",
        "    # --- FITTING ---\n",
        "\n",
        "    def _estimate_prior(self, y):\n",
        "        # Значения априорных вероятностей сохраните в `params` с ключом 'prior'\n",
        "        # Напишите свой код здесь\n",
        "        pass\n",
        "\n",
        "    def _estimate_params(self, x, y):\n",
        "        # Напишите свой код здесь\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onNEz9Mwr_f3"
      },
      "outputs": [],
      "source": [
        "# Создайте и обучите модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACb45vMbr_f3"
      },
      "outputs": [],
      "source": [
        "# Оцените качество модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_XOO1j-r_f4"
      },
      "outputs": [],
      "source": [
        "# Сравните вашу модель с аналогом sklearn (MultinomialNB)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}